{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "duckietown_stablebaseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgcb+hNHHk/zvV7h1kHEur",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aeapolimi/duckietown/blob/master/duckietown_stablebaseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWs-smIR_BD8"
      },
      "source": [
        "#Train duckietown with stable baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6gF4aXa_GQx"
      },
      "source": [
        "Environment setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnPw8GUh-IGW"
      },
      "source": [
        "import os \n",
        "if not os.path.isdir('gym-duckietown') and not os.path.isdir('../gym-duckietown'):\n",
        "  branch = \"master\" #@param ['master', 'daffy']\n",
        "  !git clone --branch {branch} https://github.com/duckietown/gym-duckietown.git\n",
        "  !pip3 install -e gym-duckietown\n",
        "if \"/gym-duckietown\" not in os.getcwd():\n",
        "  os.chdir('gym-duckietown')\n",
        "!apt install xvfb -y\n",
        "!pip3 install pyvirtualdisplay\n",
        "from pyvirtualdisplay import Display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWHDICC-_Mjo"
      },
      "source": [
        "Install stable baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii2w84aUBL6x"
      },
      "source": [
        "# Stable baseline requires tensorflow 1.x\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSVnMupWErAZ"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vze9xU8-PZK"
      },
      "source": [
        "!apt update && apt install cmake libopenmpi-dev python3-dev zlib1g-dev\n",
        "!pip3 install stable-baselines[mpi]\n",
        "#This version with mpi is apparently broken, see:\n",
        "#https://github.com/hill-a/stable-baselines/issues/464\n",
        "!pip3 install stable-baselines --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckktk_4CreKz"
      },
      "source": [
        "map_name = \"Duckietown-small_loop-v0\" #@param ['Duckietown-straight_road-v0','Duckietown-4way-v0','Duckietown-udem1-v0','Duckietown-small_loop-v0','Duckietown-small_loop_cw-v0','Duckietown-zigzag_dists-v0','Duckietown-loop_obstacles-v0','Duckietown-loop_pedestrians-v0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOWXCpQqPelZ"
      },
      "source": [
        "Wrapper to highlight lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogq5yEuS2aer"
      },
      "source": [
        "import cv2\n",
        "import gym\n",
        "from gym.spaces import Box\n",
        "\n",
        "cutted_img_height = 350 #@param {type: \"slider\", min: 0, max: 480, step:1}\n",
        "resize_ratio = 0.35 #@param {type: \"slider\", min: 0.0, max: 1.0, step:0.01}\n",
        "\n",
        "img_height = 480\n",
        "top_crop = img_height - cutted_img_height\n",
        "\n",
        "img_final_height = int(cutted_img_height * resize_ratio)\n",
        "img_final_width = int(640 * resize_ratio)\n",
        "\n",
        "def cropimg(img):\n",
        "    \"\"\"\n",
        "    Crop top of image top_crop px, they are noise most of the time\n",
        "\n",
        "    :param img: (RGB image as np array) Image to be cropped\n",
        "    \"\"\"\n",
        "    return img[top_crop:,:]\n",
        "\n",
        "def houghtransform(img):\n",
        "    \"\"\"\n",
        "    Apply Hough Line transform, for theory see:\n",
        "    https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html\n",
        "\n",
        "    :param img: (RGB image as np array)\n",
        "    \"\"\"\n",
        "    frame_BGR = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    #gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY, 3)\n",
        "    edges = cv2.Canny(frame_BGR,50,150,apertureSize = 3)\n",
        "    #minLineLength = 100\n",
        "    #maxLineGap = 10\n",
        "    #lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
        "    #for x1,y1,x2,y2 in lines[0]:\n",
        "    #    cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "    imgRGB = cv2.cvtColor(edges, cv2.COLOR_BGR2RGB)\n",
        "    return imgRGB\n",
        "\n",
        "def resizeimg(img, ratio):\n",
        "    \"\"\"\n",
        "    Resize image\n",
        "    :param img: (np array)\n",
        "    :param ratio: (float) 0<ratio<1\n",
        "    \"\"\"\n",
        "    return cv2.resize(img, (0,0), fx=ratio, fy=ratio) \n",
        "  \n",
        "def takeyellow(img):\n",
        "    \"\"\"\n",
        "    Extract yellow lines, for color ranges see:\n",
        "    https://stackoverflow.com/questions/48109650/how-to-detect-two-different-colors-using-cv2-inrange-in-python-opencv\n",
        "\n",
        "    :param img: (RGB image as np array)\n",
        "    \"\"\"\n",
        "    frame_HSV = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    frame_threshold = cv2.inRange(frame_HSV, (20,100,100), (50, 255, 255))\n",
        "    imgRGB = cv2.cvtColor(frame_threshold, cv2.COLOR_GRAY2RGB)\n",
        "    return imgRGB\n",
        "\n",
        "def takewhiteyellow(img):\n",
        "    \"\"\"\n",
        "    Extract white and yellow lines\n",
        "\n",
        "    :param img: (RGB image as np array)\n",
        "    \"\"\"\n",
        "    #white\n",
        "    sensitivity = 100\n",
        "    lower_white = np.array([0,0,255-sensitivity])\n",
        "    upper_white = np.array([255,sensitivity,255])\n",
        "    frame_HSV = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    maskwhite = cv2.inRange(frame_HSV, lower_white, upper_white)\n",
        "    img[maskwhite > 0] = (255, 0, 0)\n",
        "    img[maskwhite == 0] = (0,0,0)\n",
        "    #yellow\n",
        "    maskyellow = cv2.inRange(frame_HSV, (15,70,70), (50, 255, 255))\n",
        "    img[maskyellow > 0] = (0, 255, 0)\n",
        "    return img\n",
        "\n",
        "def white_balance(img):\n",
        "    \"\"\"\n",
        "    Grayworld assumption:\n",
        "    https://stackoverflow.com/questions/46390779/automatic-white-balancing-with-grayworld-assumption/46391574\n",
        "\n",
        "    :param img: (RGB image as np array)\n",
        "    \"\"\"\n",
        "    result = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "    avg_a = np.average(result[:, :, 1])\n",
        "    avg_b = np.average(result[:, :, 2])\n",
        "    result[:, :, 1] = result[:, :, 1] - ((avg_a - 128) * (result[:, :, 0] / 255.0) * 1.1)\n",
        "    result[:, :, 2] = result[:, :, 2] - ((avg_b - 128) * (result[:, :, 0] / 255.0) * 1.1)\n",
        "    result = cv2.cvtColor(result, cv2.COLOR_LAB2RGB)\n",
        "    return result\n",
        "\n",
        "class ObsWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(ObsWrapper, self).__init__(env)\n",
        "        self.observation_space = Box(0, 255, (img_final_height, img_final_width, 3), dtype=self.observation_space.dtype)\n",
        "        self.accept_start_angle_deg = 4\n",
        "        self.env = env\n",
        "\n",
        "    def observation(self, obs):\n",
        "        cropped = cropimg(obs)\n",
        "        resized = resizeimg(cropped, resize_ratio)\n",
        "        balanced = white_balance(resized)\n",
        "        img = takewhiteyellow(balanced)\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDmisuT60rpI"
      },
      "source": [
        "class NormalizeWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(NormalizeWrapper, self).__init__(env)\n",
        "        self.observation_space = Box(0, 1, self.observation_space.shape, dtype=self.observation_space.dtype)\n",
        "        self.env = env\n",
        "\n",
        "    def observation(self, obs):\n",
        "        obs = obs/255\n",
        "        return obs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVzrES9nRTAH"
      },
      "source": [
        "Wrapper result example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq12N95MPdap"
      },
      "source": [
        "import gym_duckietown\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "env = gym.make(map_name, accept_start_angle_deg=4)\n",
        "env = ObsWrapper(env)\n",
        "plt.imshow(env.reset())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO_x4ke9oKyt"
      },
      "source": [
        "class DtRewardWrapper(gym.RewardWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(DtRewardWrapper, self).__init__(env)\n",
        "\n",
        "    def reward(self, reward):\n",
        "        if reward == -1000:\n",
        "            reward = -10\n",
        "        elif reward > 0:\n",
        "            reward += 10\n",
        "        else:\n",
        "            reward += 4\n",
        "\n",
        "        return reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZm-kw82y2bJ"
      },
      "source": [
        "env = DtRewardWrapper(env)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcbHX4R8XWXO"
      },
      "source": [
        "env.observation_space"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lly9fjlv9UqS"
      },
      "source": [
        "env.action_space"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-trsYF4E_SG"
      },
      "source": [
        "%tensorboard --logdir ./a2c_duckieloop/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndNCPWQEM43x"
      },
      "source": [
        "NB Con lr = 0.0007 e gamma >= 0.6 reward converge a -1000, con 0.5 esce la situazione reward = 0 e la macchina fa retromarcia invece di curvare\n",
        "\n",
        "Con lr = 0.007 e gamma = 0.5 converge a -1000 nei primi 30k (CnnLstm)\n",
        "\n",
        "Con lr = 0.00007 e gamma 0.5 fa ancora retromarcia invece di curvare con 200k, con gamma 0.6 e 0.05 uguale. (CnnLstm)\n",
        "\n",
        "Con lr = 0.00007 e gamma 0.4 fa ancora retromarcia ma curva un po' curvare con 200k, ma i mean reward nel train sono piuttosto alti (>-600). (CnnLstm)\n",
        "\n",
        "0.3 come 0.4 ma reward non buoni\n",
        "\n",
        "0.1 schifo\n",
        "\n",
        "0.2 non fa neanche i rettilinei"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP7ebYLq--KF"
      },
      "source": [
        "from stable_baselines.common.vec_env import VecFrameStack\n",
        "from stable_baselines import A2C\n",
        "from stable_baselines.common.policies import CnnLstmPolicy\n",
        "from stable_baselines.common.evaluation import evaluate_policy\n",
        " \n",
        "model = A2C(\n",
        "    CnnLstmPolicy,\n",
        "    env,\n",
        "    gamma=0.337338101, #Discount reward def=0.99\n",
        "    n_steps=5,\n",
        "    learning_rate=0.0001435, #def=0.0007\n",
        "    lr_schedule='constant',\n",
        "    verbose=0,\n",
        "    tensorboard_log=\"./a2c_duckieloop/\"\n",
        "    )\n",
        " \n",
        "# Change range to train more\n",
        "if True:\n",
        "  print(\"Starting...\")\n",
        "  for time in range(10):\n",
        "    model.learn(total_timesteps=int(2e4))\n",
        "    model.save(\"a2c\"+map_name+str(1e4*time))\n",
        "    mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
        "    print(f\"#{time} Trained 10000 timesteps, mean_reward: {mean_reward}, std_reward: {std_reward}\")\n",
        "  \n",
        "  ipythondisplay.clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-O0qmH1Gw2u"
      },
      "source": [
        "# Set up fake display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xla7TYKpGx3s"
      },
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "def show_videos(video_path='', prefix=''):\n",
        "  \"\"\"\n",
        "  Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "  :param video_path: (str) Path to the folder containing videos\n",
        "  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "  \"\"\"\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0EYf0nsGy8D"
      },
      "source": [
        "from stable_baselines.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "def record_video(model, video_length=500, prefix='', video_folder='videos/'):\n",
        "  \"\"\"\n",
        "  :param model: (RL model)\n",
        "  :param video_length: (int)\n",
        "  :param prefix: (str)\n",
        "  :param video_folder: (str)\n",
        "  \"\"\"\n",
        "  eval_env = DummyVecEnv([lambda: DtRewardWrapper(ObsWrapper(gym.make(map_name, accept_start_angle_deg=4)))])\n",
        "  # Start the video at step=0 and record 500 steps\n",
        "  eval_env = VecVideoRecorder(eval_env, video_folder=video_folder,\n",
        "                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
        "                              name_prefix=prefix)\n",
        "\n",
        "  obs = eval_env.reset()\n",
        "  for _ in range(video_length):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, reward, done, _ = eval_env.step(action)\n",
        "    if done and reward < 0:\n",
        "      print(\"*** CRASHED ***\")\n",
        "      print(reward)\n",
        "    elif done:\n",
        "      print(\"SAFE\")\n",
        "      print(reward)\n",
        "    \n",
        "\n",
        "  # Close the video recorder\n",
        "  eval_env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGXCFrCJHMCF"
      },
      "source": [
        "if False:\n",
        "    time = 4\n",
        "    model_to_be_loaded = \"a2c\"+map_name+str(1e4*time)\n",
        "    model = A2C.load(model_to_be_loaded)\n",
        "if True:\n",
        "  record_video(model, video_length=500, prefix=map_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9IFe9EfHV39"
      },
      "source": [
        "if True:\n",
        "  show_videos('videos', prefix=map_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzzIyKuHq4So"
      },
      "source": [
        "# To continue the training set to True\n",
        "if False:\n",
        "  # To load a model set to True\n",
        "  if False:\n",
        "    from stable_baselines import A2C\n",
        "    model_to_be_loaded = \"a2c\"+map_name+\"\"\n",
        "    model = A2C.load(model_to_be_loaded, tensorboard_log=\"./a2c_duckieloop/\")\n",
        "    model.set_env(env)\n",
        "  for time in range(5):\n",
        "    model.learn(total_timesteps=int(1e5))\n",
        "    model.save(\"a2c\"+map_name+str(1e5*time))\n",
        "    mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
        "    print(f\"Trained 100000 timesteps, mean_reward: {mean_reward}, std_reward: {std_reward}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zbL74H6pmGR"
      },
      "source": [
        "Test parameter search using optuna:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1ZrVs53DAHe"
      },
      "source": [
        "Risultati test gamma:\n",
        "\n",
        "Promettente intorno a 0.565 - 0.567\n",
        "\n",
        "0.567113528 -> -149\n",
        "\n",
        "0.418975447 -> -202\n",
        "\n",
        "Buono intorno a 0.33 - 0.337 ma con uno strano picco negativo a 0.336\n",
        "\n",
        "0.337338101 -> -28"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJJUABxCoFmn"
      },
      "source": [
        "def objective(trial):\n",
        "\n",
        "    gamma = 0.567113528\n",
        "    lr = trial.suggest_float(\"learning_rate\", 0.00005, 0.005, log=True)\n",
        "\n",
        "    model = A2C(\n",
        "      CnnLstmPolicy,\n",
        "      env,\n",
        "      gamma=gamma,\n",
        "      n_steps=5,\n",
        "      learning_rate=lr, #def=0.0007\n",
        "      lr_schedule='constant',\n",
        "      verbose=0,\n",
        "      tensorboard_log=\"./a2c_duckieloop/\"\n",
        "    )\n",
        "\n",
        "    model.learn(total_timesteps=int(5e4))\n",
        "    mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=100)\n",
        "    print(gamma)\n",
        "    print(mean_reward)\n",
        "\n",
        "    return mean_reward\n",
        "\n",
        "if False:\n",
        "  !pip install optuna\n",
        "  import optuna\n",
        "  study = optuna.create_study(direction='maximize')\n",
        "  study.optimize(objective, n_trials=20)\n",
        "  print(study.best_params)\n",
        "  print(study.best_value)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}